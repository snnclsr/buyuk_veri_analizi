{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# Projenin içinde stopwords dosyası olmadığı için, \n",
    "# stopwordler bu adresten alındı.\n",
    "\n",
    "stopwords_filename = \"stopwords\"\n",
    "with open(stopwords_filename, \"r\") as f:\n",
    "    stopwords = f.read().split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i, me, my, myself, we, our, ours, ourselves, you, your, yours, yourself, yourselves, he, him, his, himself, she, her, hers, herself, it, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, should, now\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cümleden stopword'leri at.\n",
    "def remove_stopwords(line, stopwords):\n",
    "    return [word for word in line.split() if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dosyayı oku, küçük harfe(lowercase) dönüştür, noktalama işaretlerini\n",
    "# kaldır ve cümlelere ayır.\n",
    "# Herbir cümle/satır için stopword'leri kaldır.\n",
    "def read_file_and_rmv_stopwords(filename, table):\n",
    "    with open(filename, \"r\") as f:\n",
    "        content = f.read().lower().translate(table).split(\"\\n\")[:-1]\n",
    "        stopwords_removed = [\" \".join(remove_stopwords(line, stopwords)) for line in content]\n",
    "        return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# İçinde bulunulan klasörde \".txt\" ile biten dosyaları oku.\n",
    "# Yukarıdaki fonksiyonda açıklanan dönüşümleri uygula.\n",
    "def read_all_files(table):\n",
    "    filenames = sorted(os.listdir())\n",
    "    file_contents = {}\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_contents[file] = read_file_and_rmv_stopwords(file, table)\n",
    "            \n",
    "    return file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her bir cümle/satır için sorguyla eşleşiyor mu kontrolü yap.\n",
    "def check_for_match(line, query):\n",
    "    splitted_line = line.split()\n",
    "    line_length = len(splitted_line)\n",
    "    query_len = len(query)\n",
    "    \n",
    "    if line_length == query_len:\n",
    "        return splitted_line == query\n",
    "    \n",
    "    founded = False\n",
    "    for i in range(line_length):\n",
    "        words = splitted_line[i:i+query_len]\n",
    "        if words == query:\n",
    "            founded = True\n",
    "            \n",
    "    return founded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Noktalama işaretlerini kaldırmak için tablo.\n",
    "    table = str.maketrans({char: None for char in string.punctuation})\n",
    "\n",
    "    query = input(\"Enter your query: \")\n",
    "    query = query.translate(table)\n",
    "    final_query = remove_stopwords(query, stopwords)\n",
    "    file_contents = read_all_files(table)\n",
    "        \n",
    "    # Ana döngü. Herbir dosyadaki herbir satır için arama yap.\n",
    "    # Arama ile eşleşen satır varsa ekrana yazdır.\n",
    "    for file, content in file_contents.items():\n",
    "        founded = False\n",
    "        found_rows = []\n",
    "        print(file)\n",
    "        for i, line in enumerate(content):\n",
    "            founded = check_for_match(line, final_query)\n",
    "            if founded:\n",
    "                found_rows.append(i+1)\n",
    "            \n",
    "        if len(found_rows) > 0:\n",
    "            print(\"found at rows: \", found_rows)\n",
    "        else:\n",
    "            print(\"query not found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: justice of the ministry official\n",
      "doc1.txt\n",
      "query not found...\n",
      "doc2.txt\n",
      "query not found...\n",
      "doc3.txt\n",
      "query not found...\n",
      "doc4.txt\n",
      "found at rows:  [9]\n",
      "doc5.txt\n",
      "found at rows:  [1]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benim dökümanların içinden seçtiğim örnekler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: agency\n",
      "doc1.txt\n",
      "found at rows:  [8]\n",
      "doc2.txt\n",
      "query not found...\n",
      "doc3.txt\n",
      "found at rows:  [9]\n",
      "doc4.txt\n",
      "found at rows:  [1]\n",
      "doc5.txt\n",
      "query not found...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: fired on army \n",
      "doc1.txt\n",
      "found at rows:  [11]\n",
      "doc2.txt\n",
      "query not found...\n",
      "doc3.txt\n",
      "query not found...\n",
      "doc4.txt\n",
      "query not found...\n",
      "doc5.txt\n",
      "query not found...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query:  main approach was simple:\n",
      "doc1.txt\n",
      "query not found...\n",
      "doc2.txt\n",
      "found at rows:  [13]\n",
      "doc3.txt\n",
      "query not found...\n",
      "doc4.txt\n",
      "query not found...\n",
      "doc5.txt\n",
      "query not found...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: death\n",
      "doc1.txt\n",
      "query not found...\n",
      "doc2.txt\n",
      "query not found...\n",
      "doc3.txt\n",
      "found at rows:  [1, 5]\n",
      "doc4.txt\n",
      "found at rows:  [1, 5, 9, 13, 15]\n",
      "doc5.txt\n",
      "query not found...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
